{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KDTree\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the .xml-file\n",
    "# zip_ref = zipfile.ZipFile('../CompanyMen_v1.0-split-012-Bobby_being_angry.azp')\n",
    "zip_ref = zipfile.ZipFile('her_scene11_fuerChristian.azp')\n",
    "zip_ref.extractall('/tmp')\n",
    "tree = ET.parse('/tmp/content.xml')\n",
    "root = tree.getroot().findall('./{http://experience.univ-lyon1.fr/advene/ns}annotations')\n",
    "i=0\n",
    "ts_end=[]\n",
    "ts_begin=[]\n",
    "for child in root[0].iter():\n",
    "    if child.get('type')=='#Shot':\n",
    "        i+=1\n",
    "        for child2 in child:\n",
    "            if child2.tag=='{http://experience.univ-lyon1.fr/advene/ns}millisecond-fragment':\n",
    "                ts_end.append(round(int(child2.get('end'))/1000*25))\n",
    "                ts_begin.append(round(int(child2.get('begin'))/1000*25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_target_colors_azp(azp_path):\n",
    "    zip_ref = zipfile.ZipFile(azp_path)\n",
    "    zip_ref.extractall('/tmp')\n",
    "    tree = ET.parse('/tmp/content.xml')\n",
    "    root = tree.getroot().findall('./{http://experience.univ-lyon1.fr/advene/ns}annotations')\n",
    "    colors_target=[]\n",
    "    for child in root[0].iter():\n",
    "        if child.get('type')=='#ColourRange':\n",
    "            for child2 in child:\n",
    "                if child2.tag=='{http://experience.univ-lyon1.fr/advene/ns}content':\n",
    "                    colors_target.append(child2.text.split(','))\n",
    "    return colors_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_begin:  (23,) [0, 239, 465, 4436, 4510, 4602, 4651, 4717, 4813, 4930, 4974, 5017, 5247, 5278, 5546, 5643, 5684, 5730, 5795, 5846, 5953, 6008, 6043]\n",
      "ts_end:  (23,) [239, 465, 4436, 4510, 4602, 4651, 4717, 4813, 4930, 4974, 5017, 5247, 5278, 5546, 5643, 5684, 5730, 5795, 5846, 5953, 6008, 6043, 6387]\n"
     ]
    }
   ],
   "source": [
    "print('ts_begin: ',np.shape(ts_begin),ts_begin)\n",
    "print('ts_end: ',np.shape(ts_end),ts_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read video file frame by frame, beginning and ending with a timestamp\n",
    "def read_video_segments(video,start_frame,end_frame,resolution_width,target_colorspace):\n",
    "    resolution_height=int(round(resolution_width * 9/16))\n",
    "    resolution=(resolution_width,resolution_height)\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    frames=[]\n",
    "    vid_length=0\n",
    "    with tqdm(total=end_frame-start_frame+1) as pbar: #init the progressbar,with max length of the given segment\n",
    "        while(vid.isOpened()):\n",
    "            ret, frame = vid.read() # if ret is false, frame has no content\n",
    "            if not ret:\n",
    "                break\n",
    "            if vid_length>=start_frame:\n",
    "                frame=cv2.resize(frame,resolution) # resize the video to a different resolution\n",
    "                frame=np.array(frame,dtype='float32')\n",
    "                frames.append(frame) #add the individual frames to a list\n",
    "                pbar.update(1) #update the progressbar\n",
    "            if vid_length==end_frame:\n",
    "                pbar.update(1)\n",
    "                break\n",
    "            vid_length+=1 #increase the vid_length counter\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    frames=change_colorspace(frames,target_colorspace)\n",
    "    return frames[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_colorspace(frame_list,target_colorspace):\n",
    "    changed_frame_list=[]\n",
    "    if target_colorspace=='HSV':\n",
    "        print('HSV')\n",
    "        for frame in frame_list:\n",
    "            frame=np.array(frame,dtype='uint8')\n",
    "            frame=cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            frame=np.array(frame,dtype='float32')\n",
    "            changed_frame_list.append(frame)\n",
    "        return changed_frame_list\n",
    "    if target_colorspace=='cie-lab':\n",
    "        print('cie-lab')\n",
    "        for frame in frame_list:\n",
    "            frame=np.array(frame,dtype='uint8')\n",
    "            frame=cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "            frame=np.array(frame,dtype='float32')\n",
    "            changed_frame_list.append(frame)\n",
    "        return changed_frame_list\n",
    "    else:\n",
    "        print('rgb')\n",
    "        for frame in frame_list:\n",
    "            frame=np.array(frame,dtype='uint8')\n",
    "            frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame=np.array(frame,dtype='float32')\n",
    "            changed_frame_list.append(frame)\n",
    "        return changed_frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nns_picture(frame_list,target_colorspace,path):\n",
    "    value_to_color=fn_value_to_color(target_colorspace,path) #get the color dict \n",
    "        \n",
    "    color_value_list=[value for value in value_to_color]\n",
    "    \n",
    "    kdt = KDTree(color_value_list, leaf_size=30, metric='euclidean')  \n",
    "    #flatten the image to 1d \n",
    "    img = frame_list.reshape((frame_list.shape[0] * frame_list.shape[1], 3))     \n",
    "\n",
    "    nns = kdt.query(img, k=1, return_distance=False)\n",
    "    \n",
    "    changed_frame_aux=[]\n",
    "    for nn in tqdm(nns):\n",
    "        changed_frame_aux.append(color_value_list[nn[0]])\n",
    "    changed_frame_aux=np.asarray(changed_frame_aux,dtype='uint8')\n",
    "    changed_frame=changed_frame_aux.reshape(frame_list.shape[0],frame_list.shape[1],3)\n",
    "    return changed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_value_to_color(target_colorspace,path):\n",
    "            if (path != 'full'):\n",
    "                print('Now using colors specified in path')\n",
    "                colors_to_value_dict = {}\n",
    "                with open(path) as f:\n",
    "                    for line in f:\n",
    "                        #split lines at \"::\n",
    "                        color, rgb = line.strip().split(':')\n",
    "                        #strip the rgb-string of the parenthesis, split it up a the commas,\n",
    "                        #cast them to int and put them into a tuples\n",
    "                        rgb_value=tuple(map(int,(rgb.strip('(').strip(')').split(','))))\n",
    "                        colors_to_value_dict[color]=rgb_value\n",
    "            else:\n",
    "                colors_to_value_dict={\n",
    "                'darkred':(139,0,0),\n",
    "                'firebrick':(178,34,34),\n",
    "                'crimson':(220,20,60),\n",
    "                'red':(255,0,0),\n",
    "                'tomato':(255,99,71),\n",
    "                'salmon':(250,128,114),\n",
    "                'darkorange':(255,140,0),\n",
    "                'gold':(255,215,0),\n",
    "                'darkkhaki':(189,183,107),\n",
    "                'yellow':(255,255,0),\n",
    "                'darkolivegreen':(85,107,47),\n",
    "                'olivedrab':(107,142,35),\n",
    "                'greenyellow':(173,255,47),\n",
    "                'darkgreen':(0,100,0),\n",
    "                'aquamarine':(127,255,212),\n",
    "                'steelblue':(70,130,180),\n",
    "                'skyblue':(135,206,235),\n",
    "                'darkblue':(0,0,139),\n",
    "                'blue':(0,0,255),\n",
    "                'royalblue':(65,105,225),\n",
    "                'purple':(128,0,128),\n",
    "                'violet':(238,130,238),\n",
    "                'deeppink':(255,20,147),\n",
    "                'pink':(255,192,203),\n",
    "                'antiquewhite':(250,235,215),\n",
    "                'saddlebrown':(139,69,19),\n",
    "                'sandybrown':(244,164,96),\n",
    "                'ivory':(255,255,240),\n",
    "                'dimgrey':(105,105,105),\n",
    "                'grey':(128,128,128),\n",
    "                'silver':(192,192,192),\n",
    "                'lightgrey':(211,211,211),\n",
    "                'black':(0,0,0),\n",
    "                'white':(255,255,255),\n",
    "                'darkcyan':(0,139,139),\n",
    "                'cyan':(0,255,255),\n",
    "                'green':(0,128,0),\n",
    "                'khaki':(240,230,140),\n",
    "                'goldenrod':(218,165,32),\n",
    "                'orange':(255,165,0),\n",
    "                'coral':(255,127,80),\n",
    "                'magenta':(255,0,255),\n",
    "                'wheat':(245,222,179),\n",
    "                'skin':(255,224,189),\n",
    "                'purple4':(147,112,219)}\n",
    "\n",
    "            colors_aux={}\n",
    "            if target_colorspace=='HSV':\n",
    "                print('HSV')\n",
    "                for color in colors_to_value_dict:\n",
    "                    a = np.array((colors_to_value_dict[color]),dtype='uint8')\n",
    "                    b = a.reshape(1,1,3)\n",
    "                    c = cv2.cvtColor(b,cv2.COLOR_RGB2HSV)\n",
    "                    c=np.array(c,dtype='float32')\n",
    "                    colors_aux[color]=tuple(c.reshape(3))\n",
    "                colors_to_value_dict=colors_aux\n",
    "\n",
    "            if target_colorspace=='cie-lab':\n",
    "                print('cie-lab')\n",
    "                for color in colors_to_value_dict:\n",
    "                    a = np.array((colors_to_value_dict[color]),dtype='uint8')\n",
    "                    b = a.reshape(1,1,3)\n",
    "                    c = cv2.cvtColor(b,cv2.COLOR_RGB2LAB)\n",
    "                    c=np.array(c,dtype='float32')\n",
    "                    colors_aux[color]=tuple(c.reshape(3))\n",
    "                colors_to_value_dict=colors_aux\n",
    "\n",
    "\n",
    "            value_to_color={}\n",
    "            for color in colors_to_value_dict:\n",
    "                value_to_color[colors_to_value_dict[color]]=color\n",
    "            #purple4 is median purple\n",
    "            #skin is caucasian        \n",
    "            return value_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 15.31it/s]                       \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  3.57it/s]                       \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.08it/s]                       \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:15,  3.94s/it]                       \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:16,  4.07s/it]                       \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:17,  4.46s/it]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resolution=1920\n",
    "target_colorspace='cie-lab'\n",
    "# video_path='../../Wells_John_CompanyMen_full.mp4'\n",
    "video_path='Her_bluray_Szene 11_25fps.mp4'\n",
    "scene_all_frames_lab=[]\n",
    "for i,ts in enumerate(zip(ts_begin,ts_end)):\n",
    "    scene_all_frames_lab.append(read_video_segments(video_path,\n",
    "                                                    ts[0],ts[0]+2,resolution,target_colorspace))\n",
    "    if i==5:\n",
    "        break\n",
    "\n",
    "# full_scene_all_frames_lab=[]\n",
    "# for i,ts in enumerate(zip(ts_begin,ts_end)):\n",
    "#     full_scene_all_frames_lab.append(read_video_segments(video_path,\n",
    "#                                                     ts[0],ts[1],resolution,target_colorspace))\n",
    "#     if i==5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (6, 2, 1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "print('shape: ', np.shape(scene_all_frames_lab))\n",
    "# print('shape: ', np.shape(full_scene_all_frames_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073600/2073600 [00:00<00:00, 2147759.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073600/2073600 [00:00<00:00, 2233556.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073600/2073600 [00:00<00:00, 2180890.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073600/2073600 [00:00<00:00, 2122197.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073600/2073600 [00:00<00:00, 2114883.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073600/2073600 [00:00<00:00, 2164763.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# for i,frame_list in enumerate(scene_all_frames_lab):\n",
    "#     #index=int(len(frame_list)/2)\n",
    "#     try:\n",
    "# #         frame=frame_list[index]\n",
    "#         frame=create_nns_picture(frame_list[0],target_colorspace,'full')\n",
    "#         cv2.imwrite('key_frames/ganzer_film/2_lab_full_1920w_'+str(i)+'.png',cv2.cvtColor(frame, cv2.COLOR_LAB2BGR))\n",
    "#     except:\n",
    "#         print('no valid timestamps at '+str(i))\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_colors(frame_list,target_colorspace,path,colors_to_return=5):\n",
    "    print(str(len(frame_list))+' frames to process.')\n",
    "    value_to_color=fn_value_to_color(target_colorspace,path) #get the color dict \n",
    "\n",
    "    bins={} #bins dict for histogram\n",
    "    for value in value_to_color: #init the dict with ones for every key to avoid difficulties with divisions\n",
    "                            # because the the sum of the bins goes from 500k to 2kk this shouldn't be a problem\n",
    "        bins[value_to_color[value]]=1\n",
    "\n",
    "    color_value_list=[value for value in value_to_color] #create a list of the color_values\n",
    "\n",
    "    kdt = KDTree(color_value_list, leaf_size=30, metric='euclidean')\n",
    "    for image in tqdm(frame_list): #traverse the video\n",
    "        img = image.reshape((image.shape[0] * image.shape[1], 3)) #flatten the image to 1d   \n",
    "        nns = kdt.query(img, k=1, return_distance=False)\n",
    "        for nn in nns:\n",
    "            bins[value_to_color[color_value_list[nn[0]]]]+=1\n",
    "\n",
    "    norm_factor = len(frame_list)* np.shape(frame_list[0])[0] * np.shape(frame_list[0])[1] #normalize the bins\n",
    "    bins_norm={k:v/norm_factor*10000 for k,v in bins.items()} #scale 0-10000 for visibility\n",
    "    return bins_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_df(bins,bin_threshold=5,colors_to_return=5):\n",
    "    #create a dataframe\n",
    "    bins_sorted=list(zip(list(bins.values()),list(bins.keys())))\n",
    "    df=pd.DataFrame(bins_sorted,columns=['count','color'])\n",
    "    df.set_index('color',inplace=True) #set the colors as the index of the dataframe\n",
    "#     bin_threshold=bin_threshold/100 #scale the percentage to 0-1\n",
    "#     df = df[df>bin_threshold].dropna() #kick bins from the dataframe with precentage lower than bin_threshold \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataframes=[]\n",
    "for shot in scene_all_frames_lab:\n",
    "    bins=extract_dominant_colors(shot,target_colorspace,'colors')\n",
    "    reduced_dataframes.append(bins_to_df(bins))\n",
    "\n",
    "full_dataframes=[]\n",
    "for shot in full_scene_all_frames_lab:\n",
    "    bins=extract_dominant_colors(shot,target_colorspace,'full')\n",
    "    full_dataframes.append(bins_to_df(bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reduced_dataframes),len(full_dataframes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(reduced_dataframe_list,full_dataframe_list,ground_truth,noise_threshold):\n",
    "    # create the lists that are returned\n",
    "    # add the first entry of the histogramm to the output \n",
    "    # the 'real' output is the real_dataframe_list\n",
    "    real_dataframe_list=[0]\n",
    "    comparison=[0]\n",
    "    \n",
    "    # traverse the histograms\n",
    "    # d is the current shot, d1 the following shot\n",
    "    for i,(d,d1,e,e1) in enumerate(zip(reduced_dataframe_list,reduced_dataframe_list[1:],\n",
    "                                       full_dataframe_list,full_dataframe_list[1:])):\n",
    "        \n",
    "        #calculate the absolute change of the histograms\n",
    "        absolute_df=abs(d1-d) \n",
    "        absolute_df=absolute_df.sort_values(by='count',ascending=False)\n",
    "        \n",
    "        #apply a noise-filter to the absolute df\n",
    "#         reduced_absolute_high=reduced_absolute_df[reduced_absolute_df>noise_threshold].dropna()\n",
    "#         reduced_absolute_low=reduced_absolute_df[reduced_absolute_df<-noise_threshold].dropna()\n",
    "#         reduced_absolute_denoised=reduced_absolute_high.combine_first(reduced_absolute_low)\n",
    "        absolute_denoised=absolute_df[absolute_df>noise_threshold].dropna()\n",
    "        \n",
    "        # create the relative change, scaled to 0-100 percent\n",
    "        # they are calculated from the denoised df, to prevent errors because of the noise\n",
    "        relative_df=absolute_denoised/d*100\n",
    "        relative_df=relative_df.dropna()\n",
    "        relative_df=relative_df.sort_values(by='count',ascending=False)\n",
    "        \n",
    "        d_sorted=d.sort_values(by='count',ascending=False)\n",
    "        \n",
    "        #use the relative changes as weights for the absolute dataframe\n",
    "        weighted_absolute_df=absolute_df*relative_df\n",
    "        weighted_absolute_df=weighted_absolute_df.sort_values(by='count',ascending=False)\n",
    "\n",
    "        # if there are no elements in the denoised df, it is assumed that all changes from\n",
    "        # shot to shot are noise, in that case the current histogram is appended,\n",
    "        # else the relative histogram\n",
    "        if len(absolute_denoised)==0:\n",
    "            real_dataframe_list.append(d_sorted)\n",
    "        else:\n",
    "            real_dataframe_list.append(relative_df)\n",
    "        \n",
    "        # create a comparison table\n",
    "        relative=relative_df.head()\n",
    "        relative=relative.drop('count',axis=1)\n",
    "        relative=relative.reset_index(level=0,inplace=False)\n",
    "        relative=relative.rename(index=str,columns={'color':'relative'})\n",
    "        \n",
    "        new=weighted_absolute_df.head()\n",
    "        new=new.drop('count',axis=1)\n",
    "        new=new.reset_index(level=0,inplace=False)\n",
    "        new=new.rename(index=str,columns={'color':'reduced_new'})\n",
    "        \n",
    "        reduced_old=d_sorted.head()\n",
    "        reduced_old=reduced_old.drop('count',axis=1)\n",
    "        reduced_old=reduced_old.reset_index(level=0,inplace=False)\n",
    "        reduced_old=reduced_old.rename(index=str,columns={'color':'reduced_old'})\n",
    "        \n",
    "        full_dd=e.sort_values(by='count',ascending=False)\n",
    "        full_old=full_dd.head()\n",
    "        full_old=full_old.drop('count',axis=1)\n",
    "        full_old=full_old.reset_index(level=0,inplace=False)\n",
    "        full_old=full_old.rename(index=str,columns={'color':'full_old'})\n",
    "\n",
    "        gt=pd.DataFrame(ground_truth[i+1],columns=['ground_truth'])\n",
    "        \n",
    "        joined=pd.concat([full_old,reduced_old,new,relative,gt],axis=1)\n",
    "        comparison.append(joined)\n",
    "        \n",
    "    return {'real': real_dataframe_list,'comparison':comparison}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth=read_target_colors_azp('her_scene11_fuerChristian.azp')\n",
    "new = process_df(reduced_dataframes,full_dataframes,ground_truth,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=full_scene_all_frames_lab[3]\n",
    "index=int(len(pp)/2)\n",
    "# cv2.imwrite('key_frames/nn_by_hand.png',cv2.cvtColor(create_nns_picture(pp[index],target_colorspace,'full'), cv2.COLOR_LAB2BGR))\n",
    "np.shape(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_dict={'light_grey':pp[index][0,0], #coordinates in image are reversed \n",
    "           'grey':pp[index][43,96],\n",
    "           'brown':pp[index][31.,107],\n",
    "           'red':pp[index][111,0],\n",
    "           'black':pp[index][1,198],\n",
    "           'white':pp[index][74,54]}\n",
    "pixel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist=10000000\n",
    "min_col=''\n",
    "for c in lab_to_color:\n",
    "\n",
    "    d = euclidean(c, np.asarray((6, 130, 129)))\n",
    "    if d < min_dist:\n",
    "        min_dist=d\n",
    "        min_col=lab_to_color[c]\n",
    "print(min_col,min_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_to_color=fn_rgb_to_color('cie-lab','full')\n",
    "lab_list=[] #create a traverseable list of the rgb_values\n",
    "for lab in lab_to_color: #map the values of the dict to a list\n",
    "    lab_list.append(lab)\n",
    "lab_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "import scipy\n",
    "all_distances={}\n",
    "color_to_color={}\n",
    "for colorstr in pixel_dict:\n",
    "    #distance={}\n",
    "    dists=[]\n",
    "    print(\"gt:\",colorstr)\n",
    "\n",
    "    for lab in lab_list:\n",
    "        #print(lab,pixel_dict[pixel])\n",
    "#         print(np.asarray(lab), lab_to_color[lab], colorstr, np.asarray(pixel_dict[colorstr]))\n",
    "        cola = np.asarray(lab,dtype='float32')\n",
    "        colb = np.asarray(pixel_dict[colorstr],dtype='float32')\n",
    "        #print(cola,colb,euclidean(cola,colb))\n",
    "#         print(euclidean(np.asarray((  0, 128, 128)) , np.asarray([  6, 130, 129],dtype='uint8')))\n",
    "        dist=scipy.spatial.distance.euclidean(cola,colb)\n",
    "        #print(dist)\n",
    "        dists.append((lab_to_color[lab],dist))\n",
    "        #distance[a]=lab\n",
    "#     print((map(max,distance)))  \n",
    "#     break\n",
    "#    print(\"gt:\",colorstr)\n",
    "    print(min(dists, key = lambda t: t[1]))\n",
    "#    print(dists)\n",
    "    \n",
    "    #all_distances[pixel]=distance\n",
    "#     print(distance)\n",
    "#     break\n",
    "    #color_to_color[pixel]=min(distance.keys())#lab_to_color[distance[min(distance.keys())]]\n",
    "#     break\n",
    "#color_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "import scipy\n",
    "euclidean(np.asarray((  0, 128, 128),dtype='uint8') , np.asarray([  6, 130, 129],dtype='uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances['black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[255,255,255]\n",
    "b=[0,0,0]\n",
    "euclidean(a,a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
