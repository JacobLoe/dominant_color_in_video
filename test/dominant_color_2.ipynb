{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KDTree\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the .xml-file\n",
    "# zip_ref = zipfile.ZipFile('../CompanyMen_v1.0-split-012-Bobby_being_angry.azp')\n",
    "zip_ref = zipfile.ZipFile('her_scene11_fuerChristian.azp')\n",
    "zip_ref.extractall('/tmp')\n",
    "tree = ET.parse('/tmp/content.xml')\n",
    "root = tree.getroot().findall('./{http://experience.univ-lyon1.fr/advene/ns}annotations')\n",
    "i=0\n",
    "ts_end=[]\n",
    "ts_begin=[]\n",
    "for child in root[0].iter():\n",
    "    if child.get('type')=='#Shot':\n",
    "        i+=1\n",
    "        for child2 in child:\n",
    "            if child2.tag=='{http://experience.univ-lyon1.fr/advene/ns}millisecond-fragment':\n",
    "                ts_end.append(round(int(child2.get('end'))/1000*25))\n",
    "                ts_begin.append(round(int(child2.get('begin'))/1000*25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_target_colors_azp(azp_path):\n",
    "    zip_ref = zipfile.ZipFile(azp_path)\n",
    "    zip_ref.extractall('/tmp')\n",
    "    tree = ET.parse('/tmp/content.xml')\n",
    "    root = tree.getroot().findall('./{http://experience.univ-lyon1.fr/advene/ns}annotations')\n",
    "    colors_target=[]\n",
    "    for child in root[0].iter():\n",
    "        if child.get('type')=='#ColourRange':\n",
    "            for child2 in child:\n",
    "                if child2.tag=='{http://experience.univ-lyon1.fr/advene/ns}content':\n",
    "                    colors_target.append(child2.text.split(','))\n",
    "    return colors_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_begin:  (23,) [0, 239, 465, 4436, 4510, 4602, 4651, 4717, 4813, 4930, 4974, 5017, 5247, 5278, 5546, 5643, 5684, 5730, 5795, 5846, 5953, 6008, 6043]\n",
      "ts_end:  (23,) [239, 465, 4436, 4510, 4602, 4651, 4717, 4813, 4930, 4974, 5017, 5247, 5278, 5546, 5643, 5684, 5730, 5795, 5846, 5953, 6008, 6043, 6387]\n"
     ]
    }
   ],
   "source": [
    "print('ts_begin: ',np.shape(ts_begin),ts_begin)\n",
    "print('ts_end: ',np.shape(ts_end),ts_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read video file frame by frame, beginning and ending with a timestamp\n",
    "def read_video_segments(video,start_frame,end_frame,resolution_width,target_colorspace):\n",
    "    resolution_height=int(round(resolution_width * 9/16))\n",
    "    resolution=(resolution_width,resolution_height)\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    frames=[]\n",
    "    vid_length=0\n",
    "    with tqdm(total=end_frame-start_frame+1) as pbar: #init the progressbar,with max lenght of the given segment\n",
    "        while(vid.isOpened()):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = vid.read() # if ret is false, frame has no content\n",
    "            if not ret:\n",
    "                break\n",
    "            # skip every \"skip_frame\"\n",
    "            if vid_length>=start_frame:\n",
    "                # resize the video to a different resolution\n",
    "                frame=cv2.resize(frame,resolution)\n",
    "                frame=np.array(frame,dtype='uint8')\n",
    "                frames.append(frame) #add the individual frames to a list\n",
    "                pbar.update(1) #update the progressbar\n",
    "            if vid_length==end_frame:\n",
    "                pbar.update(1)\n",
    "                break\n",
    "            vid_length+=1 #increase the vid_length counter\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    frames=change_colorspace(frames,target_colorspace)\n",
    "    return frames[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_colorspace(frame_list,target_colorspace):\n",
    "    changed_frame_list=[]\n",
    "    if target_colorspace=='HSV':\n",
    "        print('HSV')\n",
    "        for frame in frame_list:\n",
    "            changed_frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV))\n",
    "        return changed_frame_list\n",
    "    if target_colorspace=='cie-lab':\n",
    "        print('cie-lab')\n",
    "        for frame in frame_list:\n",
    "            changed_frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2LAB))\n",
    "        return changed_frame_list\n",
    "    else:\n",
    "        print('rgb')\n",
    "        for frame in frame_list:\n",
    "            changed_frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        return changed_frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_rgb_to_color(target_colorspace,path):\n",
    "            if (path != 'full'):\n",
    "                print('Now using colors specified in path')\n",
    "                colors = {}\n",
    "                with open(path) as f:\n",
    "                    for line in f:\n",
    "                        #split lines at \"::\n",
    "                        color, rgb = line.strip().split(':')\n",
    "                        #strip the rgb-string of the parenthesis, split it up a the commas,\n",
    "                        #cast them to int and put them into a tuples\n",
    "                        rgb_value=tuple(map(int,(rgb.strip('(').strip(')').split(','))))\n",
    "                        colors[color]=rgb_value\n",
    "            else:\n",
    "                colors={'darkred':(139,0,0),\n",
    "                'firebrick':(178,34,34),\n",
    "                'crimson':(220,20,60),\n",
    "                'red':(255,0,0),\n",
    "                'tomato':(255,99,71),\n",
    "                'salmon':(250,128,114),\n",
    "                'darkorange':(255,140,0),\n",
    "                'gold':(255,215,0),\n",
    "                'darkkhaki':(189,183,107),\n",
    "                'yellow':(255,255,0),\n",
    "                'darkolivegreen':(85,107,47),\n",
    "                'olivedrab':(107,142,35),\n",
    "                'greenyellow':(173,255,47),\n",
    "                'darkgreen':(0,100,0),\n",
    "                'aquamarine':(127,255,212),\n",
    "                'steelblue':(70,130,180),\n",
    "                'skyblue':(135,206,235),\n",
    "                'darkblue':(0,0,139),\n",
    "                'blue':(0,0,255),\n",
    "                'royalblue':(65,105,225),\n",
    "                'purple':(128,0,128),\n",
    "                'violet':(238,130,238),\n",
    "                'deeppink':(255,20,147),\n",
    "                'pink':(255,192,203),\n",
    "                'antiquewhite':(250,235,215),\n",
    "                'saddlebrown':(139,69,19),\n",
    "                'sandybrown':(244,164,96),\n",
    "                'ivory':(255,255,240),\n",
    "                'dimgrey':(105,105,105),\n",
    "                'grey':(128,128,128),\n",
    "                'silver':(192,192,192),\n",
    "                'lightgrey':(211,211,211),\n",
    "                'black':(0,0,0),\n",
    "                'white':(255,255,255),\n",
    "                'darkcyan':(0,139,139),\n",
    "                'cyan':(0,255,255),\n",
    "                'green':(0,128,0),\n",
    "                'khaki':(240,230,140),\n",
    "                'goldenrod':(218,165,32),\n",
    "                'orange':(255,165,0),\n",
    "                'coral':(255,127,80),\n",
    "                'magenta':(255,0,255),\n",
    "                'wheat':(245,222,179),\n",
    "                'skin':(255,224,189),\n",
    "                'purple4':(147,112,219)}\n",
    "\n",
    "            colors_aux={}\n",
    "            if target_colorspace=='HSV':\n",
    "                print('HSV')\n",
    "                for color in colors:\n",
    "                    a = np.array((colors[color]),dtype='uint8')\n",
    "                    b = a.reshape(1,1,3)\n",
    "                    c = cv2.cvtColor(b,cv2.COLOR_RGB2HSV)\n",
    "                    colors_aux[color]=tuple(c.reshape(3))\n",
    "                colors=colors_aux\n",
    "            if target_colorspace=='cie-lab':\n",
    "                print('cie-lab')\n",
    "                for color in colors:\n",
    "                    a = np.array((colors[color]),dtype='uint8')\n",
    "                    b = a.reshape(1,1,3)\n",
    "                    c = cv2.cvtColor(b,cv2.COLOR_RGB2LAB)\n",
    "                    colors_aux[color]=tuple(c.reshape(3))\n",
    "                colors=colors_aux\n",
    "\n",
    "            rgb_to_color={}\n",
    "            for color in colors:\n",
    "                rgb_to_color[colors[color]]=color\n",
    "            #purple4 is median purple\n",
    "            #skin is caucasian        \n",
    "            return rgb_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nns_picture(frame_list,target_colorspace,path):\n",
    "    rgb_to_color=fn_rgb_to_color(target_colorspace,path) #get the color dict \n",
    "    bins={} #a dict with an entry for each for histograms \n",
    "    for rgb in rgb_to_color: #init the dict with zeros for every key\n",
    "        bins[rgb_to_color[rgb]]=0\n",
    "        \n",
    "    rgb_list=[] #create a list of the rgb_values\n",
    "    for rgb in rgb_to_color: #map the values of the dict to a list\n",
    "        rgb_list.append(rgb)\n",
    "    kdt = KDTree(rgb_list, leaf_size=30, metric='euclidean')  \n",
    "    #flatten the image to 1d \n",
    "#     img = frame_list[0].reshape((frame_list[0].shape[0] * frame_list[0].shape[1], 3))\n",
    "    img = frame_list.reshape((frame_list.shape[0] * frame_list.shape[1], 3))     \n",
    "\n",
    "    nns = kdt.query(img, k=1, return_distance=False)\n",
    "    changed_frame_aux=[]\n",
    "    for nn in tqdm(nns):\n",
    "        changed_frame_aux.append(rgb_list[nn[0]])\n",
    "    changed_frame_aux=np.asarray(changed_frame_aux,dtype='uint8')\n",
    "#     changed_frame=changed_frame_aux.reshape(frame_list[0].shape[0],frame_list[0].shape[1],3)\n",
    "    changed_frame=changed_frame_aux.reshape(frame_list.shape[0],frame_list.shape[1],3)\n",
    "    return changed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [00:01, 189.67it/s]                        \n",
      "  0%|          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [00:02, 107.28it/s]                        \n",
      "  0%|          | 0/3972 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3973it [00:19, 203.14it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:17,  4.34it/s]                        \n",
      "  0%|          | 0/93 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:17,  5.25it/s]                        \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:19,  2.68it/s]                        \n",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:19,  3.51it/s]                        \n",
      "  0%|          | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [00:18,  5.25it/s]                        \n",
      "  0%|          | 0/118 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [00:19,  6.15it/s]                        \n",
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:18,  2.46it/s]                        \n",
      "  0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:18,  2.38it/s]                        \n",
      "  0%|          | 0/231 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [00:20, 11.58it/s]                         \n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:20,  1.62it/s]                        \n",
      "  0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "270it [00:21, 12.66it/s]                         \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:22,  4.43it/s]                        \n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:20,  2.12it/s]                        \n",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:20,  2.33it/s]                        \n",
      "  0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [00:20,  3.21it/s]                        \n",
      "  0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:20,  2.58it/s]                        \n",
      "  0%|          | 0/108 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:21,  5.09it/s]                        \n",
      "  0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 35/56 [00:23<00:13,  1.51it/s]\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/345 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resolution=200\n",
    "scene_all_frames_lab=[]\n",
    "target_colorspace='cie-lab'\n",
    "# color_path='../colors'\n",
    "color_path='full'\n",
    "# video_path='../../Wells_John_CompanyMen_full.mp4'\n",
    "video_path='Her_bluray_Szene 11_25fps.mp4'\n",
    "for i,ts in enumerate(zip(ts_begin,ts_end)):\n",
    "    scene_all_frames_lab.append(read_video_segments(video_path,\n",
    "                                                    ts[0],ts[1],resolution,target_colorspace))\n",
    "#     if i==5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (23,)\n"
     ]
    }
   ],
   "source": [
    "print('shape: ', np.shape(scene_all_frames_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22400/22400 [00:00<00:00, 1637457.69it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 2038588.10it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 2039251.81it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1881343.43it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1683855.65it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1671632.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1748081.90it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1707884.05it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1443179.21it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1964298.76it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1705465.88it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1724087.23it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1726875.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22400/22400 [00:00<00:00, 1540961.29it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1792745.43it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 2056481.41it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1696044.94it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1745386.49it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1867284.30it/s]\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1984379.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 22400/22400 [00:00<00:00, 1757499.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n",
      "no valid timestamps at 21\n",
      "no valid timestamps at 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i,frame_list in enumerate(scene_all_frames_lab):\n",
    "#     print('full',len(frame_list))\n",
    "#     print('half',int(len(frame_list)/2))\n",
    "    index=int(len(frame_list)/2)\n",
    "    try:\n",
    "#         frame=frame_list[index]\n",
    "        frame=create_nns_picture(frame_list[index],target_colorspace,color_path)\n",
    "        cv2.imwrite('key_frames/ganzer_film/lab_full_200w_'+str(i)+'.png',cv2.cvtColor(frame, cv2.COLOR_LAB2BGR))\n",
    "    except:\n",
    "        print('no valid timestamps at '+str(i))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_colors(frame_list,target_colorspace,path):\n",
    "    print(str(len(frame_list))+' frames to process.')\n",
    "    rgb_to_color=fn_rgb_to_color(target_colorspace,path) #get the color dict \n",
    "    bins={} #bins dict for histograms \n",
    "    for rgb in rgb_to_color: #init the dict with ones for every key to avoid difficulties with divisions\n",
    "                            # because the the sum of the bins goes from 500k to 2kk this shouldn't be a problem\n",
    "        bins[rgb_to_color[rgb]]=1\n",
    "    rgb_list=[] #create a traverseable list of the rgb_values\n",
    "    for rgb in rgb_to_color: #map the values of the dict to a list\n",
    "        rgb_list.append(rgb)\n",
    "\n",
    "    kdt = KDTree(rgb_list, leaf_size=30, metric='euclidean')\n",
    "    for image in tqdm(frame_list): #traverse the video\n",
    "        img = image.reshape((image.shape[0] * image.shape[1], 3)) #flatten the image to 1d   \n",
    "        nns = kdt.query(img, k=1, return_distance=False)\n",
    "        for nn in nns:\n",
    "            bins[rgb_to_color[rgb_list[nn[0]]]]+=1\n",
    "    norm_factor = len(frame_list)* np.shape(frame_list[0])[0] * np.shape(frame_list[0])[1] #normalize the bins\n",
    "    bins_norm={k:v/norm_factor*10000 for k,v in bins.items()} #scale 0-10000 for visibility\n",
    "    return bins_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_df(bins,bin_threshold=5,colors_to_return=5):\n",
    "    #create a dataframe\n",
    "    bins_sorted=list(zip(list(bins.values()),list(bins.keys())))\n",
    "    df=pd.DataFrame(bins_sorted,columns=['count','color'])\n",
    "    df.set_index('color',inplace=True) #set the colors as the index of the dataframe\n",
    "#     bin_threshold=bin_threshold/100 #scale the percentage to 0-1\n",
    "#     df = df[df>bin_threshold].dropna() #kick bins from the dataframe with precentage lower than bin_threshold \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='full'\n",
    "dataframes=[]\n",
    "for shot in scene_all_frames_lab:\n",
    "    bins=extract_dominant_colors(shot,target_colorspace,color_path)\n",
    "    dataframes.append(bins_to_df(bins))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataframes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(dataframe_list,ground_truth,noise_threshold):\n",
    "    # create the lists that are returned\n",
    "    # add the first entry of the histogramm to the output \n",
    "    # the 'real' output is the real_dataframe_list\n",
    "    absolute_dataframe_list=[dataframe_list[0].sort_values(by='count',ascending=False)]\n",
    "    relative_dataframe_list=[dataframe_list[0].sort_values(by='count',ascending=False)]\n",
    "    real_dataframe_list=[dataframe_list[0].sort_values(by='count',ascending=False)]\n",
    "    comparison=[dataframe_list[0].sort_values(by='count',ascending=False)]\n",
    "    \n",
    "    # traverse the histograms\n",
    "    # d is the current shot, d1 the following shot\n",
    "    for i,d in enumerate(zip(dataframe_list,dataframe_list[1:])):\n",
    "        \n",
    "        absolute_df=d[1]-d[0] #calculate the absolute change of the histograms\n",
    "        absolute_df=absolute_df.sort_values(by='count',ascending=False)\n",
    "        absolute_dataframe_list.append(absolute_df) #add the changes to the corresponding lists\n",
    "\n",
    "        #apply a noise-filter to the absolute df\n",
    "        absolute_high=absolute_df[absolute_df>noise_threshold].dropna()\n",
    "        absolute_low=absolute_df[absolute_df<-noise_threshold].dropna()\n",
    "        absolute_denoised=absolute_high.combine_first(absolute_low)\n",
    "        \n",
    "        # create the relative change, scaled to 0-100 percent\n",
    "        # they are calculated from the denoised df, to prevent errors because of the noise\n",
    "        relative_df=absolute_denoised/d[0]*100\n",
    "        relative_df=relative_df.dropna()\n",
    "        relative_df=relative_df.sort_values(by='count',ascending=False)\n",
    "        relative_dataframe_list.append(relative_df)\n",
    "        \n",
    "        dd=d[0].sort_values(by='count',ascending=False)\n",
    "        \n",
    "        # if there are no elements in the denoised df it is assumed that all changes from\n",
    "        # shot to shot are noise, in that case the current histogram is appended,\n",
    "        # else the relative histogram\n",
    "        if len(absolute_denoised)==0:\n",
    "            real_dataframe_list.append(dd)\n",
    "        else:\n",
    "            real_dataframe_list.append(relative_df)\n",
    "        \n",
    "        new=relative_df.head()\n",
    "        new=new.drop('count',axis=1)\n",
    "        new=new.reset_index(level=0,inplace=False)\n",
    "        new=new.rename(index=str,columns={'color':'new'})\n",
    "        old=dd.head()\n",
    "        old=old.drop('count',axis=1)\n",
    "        old=old.reset_index(level=0,inplace=False)\n",
    "        old=old.rename(index=str,columns={'color':'old'})\n",
    "\n",
    "        gt=pd.DataFrame(ground_truth[i],columns=['ground_truth'])\n",
    "        \n",
    "        joined=pd.concat([old,new,gt],axis=1)\n",
    "        comparison.append(joined)\n",
    "#         print('len absolute_denoised: ',len(absolute_denoised))\n",
    "        \n",
    "    return {'real': real_dataframe_list,'comparison':comparison,'absolute':absolute_dataframe_list,'relative':relative_dataframe_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth=read_target_colors_azp('her_scene11_fuerChristian.azp')\n",
    "new = process_df(dataframes,ground_truth,100)\n",
    "# print(len(new['real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['real'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
