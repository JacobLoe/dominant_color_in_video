{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from scipy.spatial.distance import euclidean\n",
    "from sklearn.neighbors import KDTree\n",
    "# import time\n",
    "# import argparse\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from skimage.color import rgb2hsv,rgb2lab, hsv2rgb, lab2rgb\n",
    "import os\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the .xml-file\n",
    "zip_ref = zipfile.ZipFile('../CompanyMen_v1.0-split-012-Bobby_being_angry.azp')\n",
    "zip_ref.extractall('/tmp')\n",
    "tree = ET.parse('/tmp/content.xml')\n",
    "root = tree.getroot().findall('./{http://experience.univ-lyon1.fr/advene/ns}annotations')\n",
    "i=0\n",
    "ts_end=[]\n",
    "ts_begin=[]\n",
    "for child in root[0].iter():\n",
    "    if child.get('type')=='#Shot':\n",
    "        i+=1\n",
    "        for child2 in child:\n",
    "            if child2.tag=='{http://experience.univ-lyon1.fr/advene/ns}millisecond-fragment':\n",
    "                ts_end.append(round(int(child2.get('end'))/1000*25))\n",
    "                ts_begin.append(round(int(child2.get('begin'))/1000*25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_begin:  (50,) [33020, 33112, 33242, 33268, 33320, 33386, 33428, 33532, 33572, 33714, 33768, 33806, 33864, 33922, 34006, 34056, 34116, 34154, 34190, 34248, 34408, 34452, 34504, 34692, 34906, 35070, 35150, 35280, 35746, 36126, 36256, 36302, 36466, 36524, 36558, 36616, 36798, 36856, 36916, 36956, 37008, 37036, 37074, 37112, 37134, 37186, 37256, 37286, 37312, 37390]\n",
      "ts_end:  (50,) [33112, 33242, 33268, 33320, 33386, 33428, 33532, 33572, 33714, 33768, 33806, 33864, 33922, 34006, 34056, 34116, 34154, 34190, 34248, 34408, 34452, 34504, 34692, 34906, 35070, 35150, 35280, 35746, 36126, 36256, 36302, 36466, 36524, 36558, 36616, 36798, 36856, 36916, 36956, 37008, 37036, 37074, 37112, 37134, 37186, 37256, 37286, 37312, 37390, 37556]\n"
     ]
    }
   ],
   "source": [
    "print('ts_begin: ',np.shape(ts_begin),ts_begin)\n",
    "print('ts_end: ',np.shape(ts_end),ts_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read video file frame by frame, beginning and ending with a timestamp\n",
    "def read_video_segments(video,start_frame,end_frame,resolution_width,target_colorspace):\n",
    "    resolution_height=int(round(resolution_width * 9/16))\n",
    "    resolution=(resolution_width,resolution_height)\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    frames=[]\n",
    "    vid_length=0\n",
    "    with tqdm(total=end_frame-start_frame+1) as pbar: #init the progressbar,with max lenght of the given segment\n",
    "        while(vid.isOpened()):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = vid.read() # if ret is false, frame has no content\n",
    "            if not ret:\n",
    "                break\n",
    "            # skip every \"skip_frame\"\n",
    "            if vid_length>=start_frame:\n",
    "                # resize the video to a different resolution\n",
    "                frame=cv2.resize(frame,resolution)\n",
    "                frame=np.array(frame,dtype='uint8')\n",
    "                frames.append(frame) #add the individual frames to a list\n",
    "                pbar.update(1) #update the progressbar\n",
    "            if vid_length==end_frame:\n",
    "                pbar.update(1)\n",
    "                break\n",
    "            vid_length+=1 #increase the vid_length counter\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    frames=change_colorspace(frames,target_colorspace)\n",
    "    return frames[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_colorspace(frame_list,target_colorspace):\n",
    "    changed_frame_list=[]\n",
    "    if target_colorspace=='HSV':\n",
    "        print('HSV')\n",
    "        for frame in frame_list:\n",
    "            changed_frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV))\n",
    "        return changed_frame_list\n",
    "    if target_colorspace=='cie-lab':\n",
    "        print('cie-lab')\n",
    "        for frame in frame_list:\n",
    "            changed_frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2LAB))\n",
    "        return changed_frame_list\n",
    "    else:\n",
    "        print('rgb')\n",
    "        for frame in frame_list:\n",
    "            changed_frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        return changed_frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_rgb_to_color(target_colorspace,path):\n",
    "            if (path != 'full'):\n",
    "                print('Now using colors specified in path')\n",
    "                colors = {}\n",
    "                with open(path) as f:\n",
    "                    for line in f:\n",
    "                        #split lines at \"::\n",
    "                        color, rgb = line.strip().split(':')\n",
    "                        #strip the rgb-string of the parenthesis, split it up a the commas,\n",
    "                        #cast them to int and put them into a tuples\n",
    "                        rgb_value=tuple(map(int,(rgb.strip('(').strip(')').split(','))))\n",
    "                        colors[color]=rgb_value\n",
    "            else:\n",
    "                colors={'darkred':(139,0,0),\n",
    "                'firebrick':(178,34,34),\n",
    "                'crimson':(220,20,60),\n",
    "                'red':(255,0,0),\n",
    "                'tomato':(255,99,71),\n",
    "                'salmon':(250,128,114),\n",
    "                'darkorange':(255,140,0),\n",
    "                'gold':(255,215,0),\n",
    "                'darkkhaki':(189,183,107),\n",
    "                'yellow':(255,255,0),\n",
    "                'darkolivegreen':(85,107,47),\n",
    "                'olivedrab':(107,142,35),\n",
    "                'greenyellow':(173,255,47),\n",
    "                'darkgreen':(0,100,0),\n",
    "                'aquamarine':(127,255,212),\n",
    "                'steelblue':(70,130,180),\n",
    "                'skyblue':(135,206,235),\n",
    "                'darkblue':(0,0,139),\n",
    "                'blue':(0,0,255),\n",
    "                'royalblue':(65,105,225),\n",
    "                'purple':(128,0,128),\n",
    "                'violet':(238,130,238),\n",
    "                'deeppink':(255,20,147),\n",
    "                'pink':(255,192,203),\n",
    "                'antiquewhite':(250,235,215),\n",
    "                'saddlebrown':(139,69,19),\n",
    "                'sandybrown':(244,164,96),\n",
    "                'ivory':(255,255,240),\n",
    "                'dimgrey':(105,105,105),\n",
    "                'grey':(28,128,128),\n",
    "                'silver':(192,192,192),\n",
    "                'lightgrey':(211,211,211),\n",
    "                'black':(0,0,0),\n",
    "                'white':(255,255,255),\n",
    "                'darkcyan':(0,139,139),\n",
    "                'cyan':(0,255,255),\n",
    "                'green':(0,128,0),\n",
    "                'khaki':(240,230,140),\n",
    "                'goldenrod':(218,165,32),\n",
    "                'orange':(255,165,0),\n",
    "                'coral':(255,127,80),\n",
    "                'magenta':(255,0,255),\n",
    "                'wheat':(245,222,179),\n",
    "                'skin':(255,224,189),\n",
    "                'purple4':(147,112,219)}\n",
    "\n",
    "            colors_aux={}\n",
    "            if target_colorspace=='HSV':\n",
    "                print('HSV')\n",
    "                for color in colors:\n",
    "                    a = np.array((colors[color]),dtype='uint8')\n",
    "                    b = a.reshape(1,1,3)\n",
    "                    c = cv2.cvtColor(b,cv2.COLOR_RGB2HSV)\n",
    "                    colors_aux[color]=tuple(c.reshape(3))\n",
    "                colors=colors_aux\n",
    "            if target_colorspace=='cie-lab':\n",
    "                print('cie-lab')\n",
    "                for color in colors:\n",
    "                    a = np.array((colors[color]),dtype='uint8')\n",
    "                    b = a.reshape(1,1,3)\n",
    "                    c = cv2.cvtColor(b,cv2.COLOR_RGB2LAB)\n",
    "                    colors_aux[color]=tuple(c.reshape(3))\n",
    "                colors=colors_aux\n",
    "\n",
    "            rgb_to_color={}\n",
    "            for color in colors:\n",
    "                rgb_to_color[colors[color]]=color\n",
    "            #purple4 is median purple\n",
    "            #skin is caucasian        \n",
    "            return rgb_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "resolution=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [01:40,  1.07s/it]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [01:43,  1.28it/s]                          \n",
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [01:40,  3.57s/it]                        \n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:40,  1.85s/it]                         \n",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:41,  1.49s/it]                          \n",
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [01:40,  2.28s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scene_all_frames_lab=[]\n",
    "for i,ts in enumerate(zip(ts_begin,ts_end)):\n",
    "    scene_all_frames_lab.append(read_video_segments('../../Wells_John_CompanyMen_full.mp4'\n",
    "                                                    ,ts[0],ts[1],resolution,'cie-lab'))\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (6,)\n"
     ]
    }
   ],
   "source": [
    "print('shape: ', np.shape(scene_all_frames_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_colors(frame_list,target_colorspace,path):\n",
    "    print(str(len(frame_list))+' frames to process.')\n",
    "    rgb_to_color=fn_rgb_to_color(target_colorspace,path) #get the color dict \n",
    "    bins={} #bins dict for histograms \n",
    "    for rgb in rgb_to_color: #init the dict with ones for every key to avoid difficulties with divisions\n",
    "                            # because the the sum of the bins goes from 500k to 2kk this shouldn't be a problem\n",
    "        bins[rgb_to_color[rgb]]=1\n",
    "    rgb_list=[] #create a traverseable list of the rgb_values\n",
    "    for rgb in rgb_to_color: #map the values of the dict to a list\n",
    "        rgb_list.append(rgb)\n",
    "\n",
    "    kdt = KDTree(rgb_list, leaf_size=30, metric='euclidean')\n",
    "    for image in tqdm(frame_list): #traverse the video\n",
    "        img = image.reshape((image.shape[0] * image.shape[1], 3)) #flatten the image to 1d   \n",
    "        nns = kdt.query(img, k=1, return_distance=False)\n",
    "        for nn in nns:\n",
    "            bins[rgb_to_color[rgb_list[nn[0]]]]+=1\n",
    "    norm_factor = len(frame_list)* np.shape(frame_list[0])[0] * np.shape(frame_list[0])[1] #normalize the bins\n",
    "    bins_norm={k:v/norm_factor*10000 for k,v in bins.items()} #scale 0-10000 for visibility\n",
    "    return bins_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_df(bins,bin_threshold=5,colors_to_return=5):\n",
    "    #create a dataframe\n",
    "    bins_sorted=list(zip(list(bins.values()),list(bins.keys())))\n",
    "    df=pd.DataFrame(bins_sorted,columns=['count','color'])\n",
    "    df.set_index('color',inplace=True) #set the colors as the index of the dataframe\n",
    "#     bin_threshold=bin_threshold/100 #scale the percentage to 0-1\n",
    "#     df = df[df>bin_threshold].dropna() #kick bins from the dataframe with precentage lower than bin_threshold \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/92 [00:00<00:02, 40.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 frames to process.\n",
      "Now using colors specified in path\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:01<00:00, 55.96it/s]\n",
      "  5%|▍         | 6/130 [00:00<00:02, 53.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 frames to process.\n",
      "Now using colors specified in path\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:02<00:00, 54.78it/s]\n",
      " 23%|██▎       | 6/26 [00:00<00:00, 54.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 frames to process.\n",
      "Now using colors specified in path\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 56.77it/s]\n",
      " 12%|█▏        | 6/52 [00:00<00:00, 55.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 frames to process.\n",
      "Now using colors specified in path\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 55.96it/s]\n",
      "  9%|▉         | 6/66 [00:00<00:01, 56.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 frames to process.\n",
      "Now using colors specified in path\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:01<00:00, 58.10it/s]\n",
      " 14%|█▍        | 6/42 [00:00<00:00, 57.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 frames to process.\n",
      "Now using colors specified in path\n",
      "cie-lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 57.39it/s]\n"
     ]
    }
   ],
   "source": [
    "path='../colors'\n",
    "dataframes=[]\n",
    "for shot in scene_all_frames_lab:\n",
    "    bins=extract_dominant_colors(shot,'cie-lab',path)\n",
    "    dataframes.append(bins_to_df(bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(dataframe_list,noise_threshold):\n",
    "    # create the lists that are returned\n",
    "    # add the first entry of the histogramm to the output \n",
    "    # the 'real' output is the real_dataframe_list\n",
    "    absolute_dataframe_list=[dataframe_list[0].sort_values(by='count',ascending=False)+1]\n",
    "    relative_dataframe_list=[dataframe_list[0].sort_values(by='count',ascending=False)+1]\n",
    "    real_dataframe_list=[dataframe_list[0].sort_values(by='count',ascending=False)+1]\n",
    "    comparison=[]\n",
    "    \n",
    "    # traverse the histograms\n",
    "    # d is the current shot, d1 the following shot\n",
    "    for d,d1 in zip(dataframe_list,dataframe_list[1:]):\n",
    "        \n",
    "        absolute_df=d1-d #calculate the absolute change of the histograms\n",
    "        #add the changes to the corresponding lists\n",
    "        absolute_dataframe_list.append(absolute_df)\n",
    "\n",
    "        #apply a noise-filter to the absolute df\n",
    "        absolute_high=absolute_df[absolute_df>noise_threshold].dropna()\n",
    "        absolute_low=absolute_df[absolute_df<-noise_threshold].dropna()\n",
    "        absolute_denoised=absolute_high.combine_first(absolute_low)\n",
    "        \n",
    "        # create the relative change, scaled to 0-100 percent\n",
    "        # they are calculated from the denoised df, to prevent errors because of the noise\n",
    "        relative_df=absolute_denoised/d*100\n",
    "        relative_df=relative_df.dropna()\n",
    "        relative_dataframe_list.append(relative_df)\n",
    "        \n",
    "        # if there are no elements in the denoised df it is assumed that all changes from\n",
    "        # shot to shot are noise, in that case the current histogram is appended,\n",
    "        # else the relative histogram\n",
    "        if len(absolute_denoised)==0:\n",
    "            real_dataframe_list.append(d.sort_values(by='count',ascending=False))\n",
    "        else:\n",
    "            real_dataframe_list.append(relative_df.sort_values(by='count',ascending=False))\n",
    "        \n",
    "        new=relative_df.sort_values(by='count',ascending=False).head()\n",
    "        old=d.sort_values(by='count',ascending=False).head()\n",
    "        joined=pd.merge(new,old,on='color',how='outer')\n",
    "        joined=joined.rename(index=str,columns={\"count_x\":'new','count_y':'old'})\n",
    "        comparison.append(joined)\n",
    "#         print('len absolute_denoised: ',len(absolute_denoised))\n",
    "        \n",
    "    return {'real': real_dataframe_list,'comparison':comparison,'absolute':absolute_dataframe_list,'relative':relative_dataframe_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new = process_df(dataframes,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>44.891386</td>\n",
       "      <td>929.973797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>9.940865</td>\n",
       "      <td>6522.243789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grey</th>\n",
       "      <td>-54.113757</td>\n",
       "      <td>1484.627329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>-93.304000</td>\n",
       "      <td>198.422943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark_cyan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>851.324728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 new          old\n",
       "color                            \n",
       "brown      44.891386   929.973797\n",
       "black       9.940865  6522.243789\n",
       "grey      -54.113757  1484.627329\n",
       "white     -93.304000   198.422943\n",
       "dark_cyan        NaN   851.324728"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['comparison'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['comparison'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,frame_list in enumerate(scene_all_frames_lab):\n",
    "#     cv2.imwrite('key_frames/'+str(i)+'.png',cv2.cvtColor(frame_list[0], cv2.COLOR_LAB2BGR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
