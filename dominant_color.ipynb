{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read video file frame by frame, beginning and ending with a timestamp\n",
    "def read_video_segments(video,start_frame,end_frame,resolution_width=200):\n",
    "    resolution_height=int(round(resolution_width * 9/16))\n",
    "    resolution=(resolution_width,resolution_height)\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    frames=[]\n",
    "    vid_length=0\n",
    "    with tqdm(total=end_frame-start_frame) as pbar: #init the progressbar,with max lenght of the given segment\n",
    "        while(vid.isOpened()):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = vid.read() # if ret is false, frame has no content\n",
    "            if not ret:\n",
    "                break\n",
    "            # skip every \"skip_frame\"\n",
    "            if vid_length>=start_frame:\n",
    "                # resize the video to a different resolution\n",
    "                frame=cv2.resize(frame,resolution)\n",
    "                frames.append(frame) #add the individual frames to a list\n",
    "                pbar.update() #update the progressbar\n",
    "            if vid_length==end_frame:\n",
    "                pbar.update()\n",
    "                break\n",
    "            vid_length+=1 #increase the vid_length counter\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read video file frame by frame, beginning and ending with a timestamp\n",
    "def read_video_segments2(video,start_frame,end_frame,resolution_width=200):\n",
    "    resolution_height=int(round(resolution_width * 9/16))\n",
    "    resolution=(resolution_width,resolution_height)\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    frames=[]\n",
    "    vid_length=0\n",
    "    while(vid.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = vid.read() # if ret is false, frame has no content\n",
    "        if not ret:\n",
    "            break\n",
    "        # skip every \"skip_frame\"\n",
    "        if vid_length>=start_frame:\n",
    "            # resize the video to a different resolution\n",
    "            frame=cv2.resize(frame,resolution)\n",
    "            frames.append(frame) #add the individual frames to a list\n",
    "        if vid_length==end_frame:\n",
    "            break\n",
    "        vid_length+=1 #increase the vid_length counter\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_color(frame_list):\n",
    "    print(str(len(frame_list))+' frames to process.')\n",
    "    start=time.time()\n",
    "    rgb_to_color=fn_rgb_to_color() #get the color dict \n",
    "    bins={} #a dict with an entry for each for histograms \n",
    "    for rgb in rgb_to_color: #init the dict with zeros for every key\n",
    "        bins[rgb_to_color[rgb]]=0\n",
    "        \n",
    "    rgb_list=[] #create a list of the rgb_values\n",
    "    for rgb in rgb_to_color: #map the values of the dict to a list\n",
    "        rgb_list.append(rgb)\n",
    "    i = 0\n",
    "\n",
    "    kdt = KDTree(rgb_list, leaf_size=30, metric='euclidean')  \n",
    "    for image in frame_list: #traverse the video\n",
    "        #flatten the image to 1d \n",
    "        img = image.reshape((image.shape[0] * image.shape[1], 3))     \n",
    "        nns = kdt.query(img, k=1, return_distance=False)\n",
    "        for nn in nns:\n",
    "            bins[rgb_to_color[rgb_list[nn[0]]]]+=1\n",
    "        i+=1\n",
    "        end=time.time()\n",
    "        print('Finished '+str(i)+',time: '+str(end-start))\n",
    "        norm_factor = len(frame_list)* np.shape(frame_list[0])[0] * np.shape(frame_list[0])[1]#normalize the bins\n",
    "        bins_norm={k:v/norm_factor for k,v in bins.items()}\n",
    "    return bins_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_df(bins,bin_threshold=5,colors_to_return=5):\n",
    "    #create a dataframe, sorted descending by count\n",
    "    bins_sorted=sorted(zip(list(bins.values()),list(bins.keys())),reverse=True)\n",
    "    df=pd.DataFrame(bins_sorted,columns=['count','color'])\n",
    "    df.set_index('color',inplace=True) #set the colors as the index of the dataframe\n",
    "    bin_threshold=bin_threshold/100 #scale the percentage to 0-1\n",
    "    df = df[df>bin_threshold].dropna() #kick bins from the dataframe with precentage lower than bin_threshold \n",
    "    return df.head(colors_to_return)#return the color_return highest bins, default 5, if less bins then\n",
    "                                    #color_return are there return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_rgb_to_color(*path):\n",
    "    if not ('no'):\n",
    "        path=str(path)[2:-3] #to get rid of the of the *args things\n",
    "        rgb_to_color = {}\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                #split lines at \"::\n",
    "                color, rgb = line.strip().split(':')\n",
    "                #strip the rgb-string of the parenthesis, split it up a the commas,\n",
    "                #cast them to int and put them into a tuples\n",
    "                rgb_value=tuple(map(int,(rgb.strip('(').strip(')').split(','))))\n",
    "                rgb_to_color[rgb_value] = color\n",
    "    else:\n",
    "        colors={'darkred':(139,0,0),\n",
    "        'firebrick':(178,34,34),\n",
    "        'crimson':(220,20,60),\n",
    "        'red':(255,0,0),\n",
    "        'tomato':(255,99,71),\n",
    "        'salmon':(250,128,114),\n",
    "        'darkorange':(255,140,0),\n",
    "        'gold':(255,215,0),\n",
    "        'darkkhaki':(189,183,107),\n",
    "        'yellow':(255,255,0),\n",
    "        'darkolivegreen':(85,107,47),\n",
    "        'olivedrab':(107,142,35),\n",
    "        'greenyellow':(173,255,47),\n",
    "        'darkgreen':(0,100,0),\n",
    "        'aquamarine':(127,255,212),\n",
    "        'steelblue':(70,130,180),\n",
    "        'skyblue':(135,206,235),\n",
    "        'darkblue':(0,0,139),\n",
    "        'blue':(0,0,255),\n",
    "        'royalblue':(65,105,225),\n",
    "        'purple':(128,0,128),\n",
    "        'violet':(238,130,238),\n",
    "        'deeppink':(255,20,147),\n",
    "        'pink':(255,192,203),\n",
    "        'antiquewhite':(250,235,215),\n",
    "        'saddlebrown':(139,69,19),\n",
    "        'sandybrown':(244,164,96),\n",
    "        'ivory':(255,255,240),\n",
    "        'dimgrey':(105,105,105),\n",
    "        'grey':(28,128,128),\n",
    "        'silver':(192,192,192),\n",
    "        'lightgrey':(211,211,211),\n",
    "        'black':(0,0,0),\n",
    "        'white':(255,255,255),\n",
    "        'darkcyan':(0,139,139),\n",
    "        'cyan':(0,255,255),\n",
    "        'green':(0,128,0),\n",
    "        'khaki':(240,230,140),\n",
    "        'goldenrod':(218,165,32),\n",
    "        'orange':(255,165,0),\n",
    "        'coral':(255,127,80),\n",
    "        'magenta':(255,0,255),\n",
    "        'wheat':(245,222,179),\n",
    "        'skin':(255,224,189),\n",
    "        'purple4':(147,112,219)}\n",
    "        rgb_to_color={}\n",
    "        for color in colors:\n",
    "            rgb_to_color[colors[color]]=color\n",
    "        #purple4 is median purple\n",
    "        #skin is caucasian\n",
    "    return rgb_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the .xml-file\n",
    "tree = ET.parse('zip/content.xml')\n",
    "root = tree.getroot().findall('./{http://experience.univ-lyon1.fr/advene/ns}annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33020.5, 33112.5]\n",
      "[33112.5, 33242.5]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "end=[]\n",
    "begin=[]\n",
    "for child in root[0].iter():\n",
    "    if child.get('type')=='#Shot':\n",
    "        i+=1\n",
    "        for child2 in child:\n",
    "            if child2.tag=='{http://experience.univ-lyon1.fr/advene/ns}millisecond-fragment':\n",
    "                           end.append(int(child2.get('end'))/1000*25)\n",
    "                           begin.append(int(child2.get('begin'))/1000*25)\n",
    "        if i==2:\n",
    "            break\n",
    "print(begin)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid1=read_video_segments2('/home/jacob/Downloads/Wells_John_CompanyMen_full.mp4',begin[0],begin[0]+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with tqdm(total=75) as pbar:\n",
    "    while i!=199:\n",
    "        if(i%2==0):\n",
    "            pbar.update()\n",
    "            time.sleep(0.1)\n",
    "            print(i)\n",
    "        if(i==150):\n",
    "            pbar.update()\n",
    "            break\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [00:01, 173.05it/s]                         \n"
     ]
    }
   ],
   "source": [
    "x = read_video_segments('videos/red.mp4',10,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# black=np.array([[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]],\n",
    "#                 [[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]],\n",
    "#                 [[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]]])\n",
    "# red=np.array([[[255,0,0],[255,0,0],[255,0,0],[255,0,0],[255,0,0]],\n",
    "#              [[255,0,0],[255,0,0],[255,0,0],[255,0,0],[255,0,0]],\n",
    "#               [[255,0,0],[255,0,0],[255,0,0],[255,0,0],[255,0,0]]])\n",
    "# green=np.array([[[0,255,0],[0,255,0],[0,255,0],[0,255,0],[0,255,0]],\n",
    "#                [[0,255,0],[0,255,0],[0,255,0],[0,255,0],[0,255,0]],\n",
    "#                [[0,255,0],[0,255,0],[0,255,0],[0,255,0],[0,255,0]]])\n",
    "# blue=np.array([[[0,0,255],[0,0,255],[0,0,255],[0,0,255],[0,0,255]],\n",
    "#               [[0,0,255],[0,0,255],[0,0,255],[0,0,255],[0,0,255]],\n",
    "#               [[0,0,255],[0,0,255],[0,0,255],[0,0,255],[0,0,255]]])\n",
    "# white=np.array([[[255,255,255],[255,255,255],[255,255,255],[255,255,255],[255,255,255]],\n",
    "#                [[255,255,255],[255,255,255],[255,255,255],[255,255,255],[255,255,255]],\n",
    "#                [[255,255,255],[255,255,255],[255,255,255],[255,255,255],[255,255,255]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=[red,blue,red,blue]\n",
    "# print(np.shape(a))\n",
    "# assert x == extract_dominant_color(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = read_video_segments('videos/red.mp4',0,9,5)\n",
    "# print(np.shape(b))\n",
    "# assert np.shape(b)==(2,3,5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x ={'antiquewhite': 0.0,'aquamarine': 0.0,'black': 0.0,'blue': 0.5,'coral': 0.0, 'crimson': 0.0, 'cyan': 0.0, 'darkblue': 0.0,\n",
    "#  'darkcyan': 0.0, 'darkgreen': 0.0, 'darkkhaki': 0.0, 'darkolivegreen': 0.0,'darkorange': 0.0, 'darkred': 0.0, 'deeppink': 0.0, 'dimgrey': 0.0,\n",
    "#  'firebrick': 0.0, 'gold': 0.0, 'goldenrod': 0.0, 'green': 0.0,'greenyellow': 0.0, 'grey': 0.0, 'ivory': 0.0, 'khaki': 0.0,\n",
    "#  'lightgrey': 0.0, 'magenta': 0.0, 'olivedrab': 0.0, 'orange': 0.0,'pink': 0.0, 'purple': 0.0, 'purple4': 0.0, 'red': 0.5,\n",
    "#  'royalblue': 0.0, 'saddlebrown': 0.0, 'salmon': 0.0, 'sandybrown': 0.0,'silver': 0.0, 'skin': 0.0, 'skyblue': 0.0, 'steelblue': 0.0,\n",
    "#  'tomato': 0.0, 'violet': 0.0, 'wheat': 0.0, 'white': 0.0, 'yellow': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
