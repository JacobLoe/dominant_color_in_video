{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can I start from specific timestamps ?\n",
    "\n",
    "what happens for skip_frames=0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read video file frame by frame\n",
    "def read_video(video,skip_frames,resolution_width):\n",
    "    resolution_height=int(resolution_width * 9/16)\n",
    "    resolution=(resolution_width,resolution_height)\n",
    "#     res_dict={'1':(120,90),'2':(240,135),'3':(480,270)}\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    frames=[]\n",
    "    vid_length=0\n",
    "    while(vid.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = vid.read() # if ret is false, frame has no content\n",
    "        # resize the video to a different resolution\n",
    "        if ret:\n",
    "            frame=cv2.resize(frame,resolution)\n",
    "        # skip every \"skip_frame\"\n",
    "        if vid_length%skip_frames==0:\n",
    "            frames.append(frame) #add the individual frames to a list\n",
    "        vid_length+=1 #increase the vid_length counter\n",
    "        if not ret:\n",
    "            break\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominant Color Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_color(frame_list,bin_threshold=0.05,colors_to_return=5):\n",
    "    print(str(len(frame_list))+' frames to process.')\n",
    "    start=time.time()\n",
    "    rgb_to_color=fn_rgb_to_color() #get the color dict \n",
    "    bins={} #bins dict for histograms \n",
    "    for rgb in rgb_to_color: #init the dict with zeros for every key\n",
    "        bins[rgb_to_color[rgb]]=0\n",
    "    rgb_list=[] #create a traverseable list of the rgb_values\n",
    "    for rgb in rgb_to_color: #map the values of the dict to a list\n",
    "        rgb_list.append(rgb)\n",
    "    i = 0\n",
    "    for image in frame_list: #traverse the video\n",
    "        #flatten the image to 1d \n",
    "        img = image.reshape((image.shape[0] * image.shape[1], 3))     \n",
    "        for pixel in img: # do nearest neighbour search on every pixel every color in the list\n",
    "            bin_aux=[]\n",
    "            #get the euclidean distance between the colors and the current pixel\n",
    "            for rgb in rgb_list:\n",
    "                bin_aux.append(euclidean(pixel,rgb))\n",
    "            # get the index of the color,which has the smallest distance, in rgb_list\n",
    "            min_pos = np.argmin(bin_aux)\n",
    "            #increment the respective color \n",
    "            bins[rgb_to_color[rgb_list[min_pos]]]+=1\n",
    "        i+=1\n",
    "        end=time.time()\n",
    "        print('Finished '+str(i)+',time: '+str(end-start))\n",
    "    #create a dataframe, sorted descending by count\n",
    "    bins_sorted=sorted(zip(list(bins.values()),list(bins.keys())),reverse=True)\n",
    "    df=pd.DataFrame(bins_sorted,columns=['count','color'])\n",
    "    df.set_index('color',inplace=True) #set the colors as the index of the dataframe\n",
    "    norm_factor = len(frame_list)* np.shape(frame_list[0])[0] * np.shape(frame_list[0])[1]  #normalize the bins\n",
    "    df=df/norm_factor \n",
    "    df = df[df>bin_threshold].dropna() #kick bins from the dataframe with precentage lower than bin_threshold \n",
    "    return df.head(colors_to_return)#return the color_return highest bins, default 5, if less bins then\n",
    "                                #color_return are there return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_rgb_to_color():\n",
    "    colors={'darkred':(139,0,0),\n",
    "    'firebrick':(178,34,34),\n",
    "    'crimson':(220,20,60),\n",
    "    'red':(255,0,0),\n",
    "    'tomato':(255,99,71),\n",
    "    'salmon':(250,128,114),\n",
    "    'dark_orange':(255,140,0),\n",
    "    'gold':(255,215,0),\n",
    "    'dark_khaki':(189,183,107),\n",
    "    'yellow':(255,255,0),\n",
    "    'dark_olive_green':(85,107,47),\n",
    "    'olive_drab':(107,142,35),\n",
    "    'green_yellow':(173,255,47),\n",
    "    'dark_green':(0,100,0),\n",
    "    'aqua_marine':(127,255,212),\n",
    "    'steel_blue':(70,130,180),\n",
    "    'sky_blue':(135,206,235),\n",
    "    'dark_blue':(0,0,139),\n",
    "    'blue':(0,0,255),\n",
    "    'royal_blue':(65,105,225),\n",
    "    'purple':(128,0,128),\n",
    "    'violet':(238,130,238),\n",
    "    'deep_pink':(255,20,147),\n",
    "    'pink':(255,192,203),\n",
    "    'antique_white':(250,235,215),\n",
    "    'saddle_brown':(139,69,19),\n",
    "    'sandy_brown':(244,164,96),\n",
    "    'ivory':(255,255,240),\n",
    "    'dim_grey':(105,105,105),\n",
    "    'grey':(28,128,128),\n",
    "    'silver':(192,192,192),\n",
    "    'light_grey':(211,211,211),\n",
    "    'black':(0,0,0),\n",
    "    'white':(255,255,255),\n",
    "    'dark_cyan':(0,139,139),\n",
    "    'cyan':(0,255,255),\n",
    "    'green':(0,128,0),\n",
    "    'khaki':(240,230,140),\n",
    "    'golden_rod':(218,165,32),\n",
    "    'orange':(255,165,0),\n",
    "    'coral':(255,127,80),\n",
    "    'magenta':(255,0,255),\n",
    "    'wheat':(245,222,179),\n",
    "    'skin':(255,224,189),\n",
    "    'purple4':(147,112,219)}\n",
    "    rgb_to_color={}\n",
    "    for color in colors:\n",
    "        rgb_to_color[colors[color]]=color\n",
    "    #purple4 is median purple\n",
    "    #skin is caucasian\n",
    "    return rgb_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 240,135\n",
    "# frames_2 = read_video('/home/jacob/Downloads/IMG_2525.MOV',2,(240,135))\n",
    "# frames_8 = read_video('/home/jacob/Downloads/IMG_2525.MOV',8,(240,135))\n",
    "# frames_32 = read_video('/home/jacob/Downloads/IMG_2525.MOV',32,(240,135))\n",
    "# print(len(frames_2),len(frames_8),len(frames_32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 120,90\n",
    "# frames_2_2 = read_video('/home/jacob/Downloads/IMG_2525.MOV',2,(120,90))\n",
    "# frames_8_2 = read_video('/home/jacob/Downloads/IMG_2525.MOV',8,(120,90))\n",
    "# frames_32_2 = read_video('/home/jacob/Downloads/IMG_2525.MOV',32,(120,90))\n",
    "# print(len(frames_2_2),len(frames_8_2),len(frames_32_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with (640,360) one frame takes 127 seconds\n",
    "- with (480,270) ....\n",
    "- with (240,135) one frame takes 17 seconds\n",
    "- with (120,90) one frame takes 5 seconds\n",
    "- with (60,45) one frame takes 1.5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 frames to process.\n",
      "Finished 1,time: 3.5499818325042725\n",
      "Finished 2,time: 7.090299844741821\n",
      "Finished 3,time: 10.579890251159668\n",
      "Finished 4,time: 14.051212549209595\n",
      "Finished 5,time: 17.52706503868103\n",
      "Finished 6,time: 20.972081661224365\n"
     ]
    }
   ],
   "source": [
    "frames_8_2_red = read_video('videos/red.mp4',200,120)\n",
    "df_8_2_red = extract_dominant_color(frames_8_2_red,bin_threshold=0.02)\n",
    "\n",
    "# frames_32_2_red = read_video('red.mp4',32,(120,90))\n",
    "\n",
    "# frames_8_2_green = read_video('green.mp4',8,(120,90))\n",
    "# frames_32_2_green = read_video('green.mp4',32,(120,90))\n",
    "\n",
    "# frames_8_2_yellow = read_video('yellow.mp4',8,(120,90))\n",
    "# frames_32_2_yellow = read_video('yellow.mp4',32,(120,90))\n",
    "\n",
    "# frames_8_2_blue = read_video('blue.mp4',8,(120,90))\n",
    "# frames_32_2_blue = read_video('blue.mp4',32,(120,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.297595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark_olive_green</th>\n",
       "      <td>0.204830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dim_grey</th>\n",
       "      <td>0.169486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purple4</th>\n",
       "      <td>0.067600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purple</th>\n",
       "      <td>0.066812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "color                     \n",
       "black             0.297595\n",
       "dark_olive_green  0.204830\n",
       "dim_grey          0.169486\n",
       "purple4           0.067600\n",
       "purple            0.066812"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8_2_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8_2_red = extract_dominant_color(frames_8_2_red,rgb_to_color)\n",
    "# df_32_2_red = extract_dominant_color(frames_32_2_red,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8_2_green = extract_dominant_color(frames_8_2_green,rgb_to_color)\n",
    "# df_32_2_green = extract_dominant_color(frames_32_2_green,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8_2_yellow = extract_dominant_color(frames_8_2_yellow,rgb_to_color)\n",
    "# df_32_2_yellow = extract_dominant_color(frames_32_2_yellow,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8_2_blue = extract_dominant_color(frames_8_2_blue,rgb_to_color)\n",
    "# df_32_2_blue = extract_dominant_color(frames_32_2_blue,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('red','\\n',df_8_2_red.tail(),'\\n',df_32_2_red.tail(),'\\n')\n",
    "# print('green','\\n',df_8_2_green.tail(),'\\n',df_32_2_green.tail(),'\\n')\n",
    "# print('yellow','\\n',df_8_2_yellow.tail(),'\\n',df_32_2_yellow.tail(),'\\n')\n",
    "# print('blue','\\n',df_8_2_blue.tail(),'\\n',df_32_2_blue.tail(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_8_2_red = read_video('red.mp4',8,(60,45))\n",
    "\n",
    "# frames_8_2_green = read_video('green.mp4',8,(120,90))\n",
    "\n",
    "# frames_8_2_yellow = read_video('yellow.mp4',8,(120,90))\n",
    "\n",
    "# frames_8_2_blue = read_video('blue.mp4',8,(120,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8_2_red = extract_dominant_color(frames_8_2_red,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8_2_red.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will take 10 and 2.6 hours respectively, so I won't touch them\n",
    "# bins_2 = extract_dominant_color(frames_2,rgb_to_color)\n",
    "# bins_8 = extract_dominant_color(frames_8,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins_32 = extract_dominant_color(frames_32,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins_2_2 = extract_dominant_color(frames_2_2,rgb_to_color)\n",
    "# bins_8_2 = extract_dominant_color(frames_8_2,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins_32_2 = extract_dominant_color(frames_32_2,rgb_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get bins into dataframes for better comparison\n",
    "# bins_32_sorted=sorted(zip(list(bins_32.values()),list(bins_32.keys())))\n",
    "# bins_8_2_sorted=sorted(zip(list(bins_8_2.values()),list(bins_8_2.keys())))\n",
    "# bins_32_2_sorted=sorted(zip(list(bins_32_2.values()),list(bins_32_2.keys())))\n",
    "\n",
    "# df_32=pd.DataFrame(bins_32_sorted,columns=['count','color'])\n",
    "# df_8_2=pd.DataFrame(bins_8_2_sorted,columns=['count','color'])\n",
    "# df_32_2=pd.DataFrame(bins_32_2_sorted,columns=['count','color'])\n",
    "\n",
    "# df_32.set_index('color',inplace=True)\n",
    "# df_8_2.set_index('color',inplace=True)\n",
    "# df_32_2.set_index('color',inplace=True)\n",
    "# df_32.tail()\n",
    "# # df_8_2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_8_2\n",
    "\n",
    "steel_blue\t259912\n",
    "\n",
    "white\t284117\n",
    "\n",
    "dim_grey\t1108648\n",
    "\n",
    "black\t1311002\n",
    "\n",
    "dark_olive_green\t1778223\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "df_32\n",
    "\n",
    "steel_blue\t194958\n",
    "\n",
    "white\t211503\n",
    "\n",
    "dim_grey\t833335\n",
    "\n",
    "black\t983867\n",
    "\n",
    "dark_olive_green\t1336795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_32_2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_32_2\n",
    "\n",
    "steel_blue\t64574\n",
    "\n",
    "white\t70615\n",
    "\n",
    "dim_grey\t278010\n",
    "\n",
    "black\t328651\n",
    "\n",
    "dark_olive_green\t445648"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
